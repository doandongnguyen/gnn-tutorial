{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Auto-Encoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "This tutorial demonstrates the use of Graph Auto-Encoders (GAEs) and Variational Graph Auto-Encoders (VGAEs) to perform unsupervised learning on a graph. The models will be implemented with PyTorch and PyG (torch geometric) (a <a href='https://github.com/tkipf/gae'>tensorflow implementation</a> has been produced by the author of VGAE).\n",
    "To demonstrate the suitably of the models' embeddings, we show how unsupervised training using only the reconstruction loss improves performance on a link prediction task that the model is not directly optimising for."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "Here we load required libraries, define paths to data, and define some helper functions. **Feel free to skip this section.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datetime import datetime\n",
    "from torch_geometric.nn import GCNConv, VGAE\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from tensorboardX import SummaryWriter\n",
    "from torch_geometric.nn.models.autoencoder import EPS, MAX_LOGVAR\n",
    "import torch_geometric.transforms as T\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.utils import to_networkx, train_test_split_edges\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn.inits import reset\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "from pandas import DataFrame as df\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "from torch_geometric.utils import (negative_sampling, remove_self_loops, add_self_loops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the path to save datasets\n",
    "fp_data = \"./datasets/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Citeseer\n",
    "The citeseer graph is accessible through PyG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset - small download on first run\n",
    "dataset = Planetoid(root=\"./datasets/citeseer\", name=\"Citeseer\")\n",
    "data = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num nodes = 3327\n",
      "num edges = 9104\n",
      "num features = 3703\n"
     ]
    }
   ],
   "source": [
    "# explore key features of the graph\n",
    "print('num nodes =', data.num_nodes)\n",
    "print('num edges =', data.num_edges)\n",
    "print('num features =', data.num_node_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>Useful PyG Citeseer graph attributes</strong>\n",
    "<table width=\"75%\">\n",
    "    <header>\n",
    "        <th style=\"text-align:left\">Name</th>\n",
    "        <th style=\"text-align:left\">Attribute</th>\n",
    "        <th style=\"text-align:left\">Shape</th>\n",
    "    </header>\n",
    "    <tr>\n",
    "        <td style=\"text-align:left\">Node Feature Matrix</td>\n",
    "        <td style=\"text-align:left\">data.x</td>\n",
    "        <td style=\"text-align:left\">(num nodes, num features)</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"text-align:left\">Edge Index</td>\n",
    "        <td style=\"text-align:left\">data.edge_index</td>\n",
    "        <td style=\"text-align:left\">(2, num edges)</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"text-align:left\">Node Classes</td>\n",
    "        <td style=\"text-align:left\">data.y</td>\n",
    "        <td style=\"text-align:left\">(num nodes, )</td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a plot function using networkx\n",
    "def plot(x, y, edge_index):\n",
    "    \"\"\"\n",
    "    plot a graph using networkx\n",
    "    :param x: feature matrix, shape (n nodes, n features)\n",
    "    :param y: node classes, shape (n nodes)\n",
    "    :param edge_index: edge index in coo format, shape (2, n edges)\n",
    "    \"\"\"\n",
    "    graph = to_networkx(Data(x=x, y=y, edge_index=edge_index))\n",
    "    nx.draw_networkx(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can plot this graph, though with 3327 nodes it is not very helpful\n",
    "#plot(data.x, data.y, data.edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instead we can select and plot a smaller sub-graph\n",
    "#plot(None, None, data.edge_index[:, :10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data for edge prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num train edges 7740\n"
     ]
    }
   ],
   "source": [
    "# To perform edge prediction, we need to split the graph's edges intro train and test sets\n",
    "data.train_mask = data.val_mask = data.test_mask = data.y = None\n",
    "data = train_test_split_edges(data)\n",
    "# Note that data.edge_index is no longer available, as edges have been distributed between train and test\n",
    "print('num train edges', data.train_pos_edge_index.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n"
     ]
    }
   ],
   "source": [
    "# Get the device to use for training our model\n",
    "dev = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('CUDA available:', torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We then register the relevant data to the device in use\n",
    "x = data.x.to(dev)  # feature matrix\n",
    "train_pos_edge_index = data.train_pos_edge_index.to(dev)  # index of true positive edges in the train set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAE Model\n",
    "To understand GAEs, we show the models as constructed by PyG. Alternatively, these can be imported directly from torch_geometric.nn\n",
    " which contains methods to:\n",
    " \n",
    "Importantly, the GAE class includes methods to:\n",
    "<ul>\n",
    "    <li>apply the encoder and decoder</li>\n",
    "    <li>calculate reconstruction loss</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the GAE class\n",
    "\n",
    "class GAE(torch.nn.Module):\n",
    "    r\"\"\"The Graph Auto-Encoder model from the\n",
    "    `\"Variational Graph Auto-Encoders\" <https://arxiv.org/abs/1611.07308>`_\n",
    "    paper based on user-defined encoder and decoder models.\n",
    "\n",
    "    Args:\n",
    "        encoder (Module): The encoder module.\n",
    "        decoder (Module, optional): The decoder module. If set to :obj:`None`,\n",
    "            will default to the\n",
    "            :class:`torch_geometric.nn.models.InnerProductDecoder`.\n",
    "            (default: :obj:`None`)\n",
    "    \"\"\"\n",
    "    def __init__(self, encoder, decoder=None):\n",
    "        super(GAE, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = InnerProductDecoder() if decoder is None else decoder\n",
    "        GAE.reset_parameters(self)\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        reset(self.encoder)\n",
    "        reset(self.decoder)\n",
    "\n",
    "\n",
    "    def encode(self, *args, **kwargs):\n",
    "        r\"\"\"Runs the encoder and computes node-wise latent variables.\"\"\"\n",
    "        return self.encoder(*args, **kwargs)\n",
    "\n",
    "\n",
    "    def decode(self, *args, **kwargs):\n",
    "        r\"\"\"Runs the decoder and computes edge probabilities.\"\"\"\n",
    "        return self.decoder(*args, **kwargs)\n",
    "\n",
    "\n",
    "    def recon_loss(self, z, pos_edge_index):\n",
    "        r\"\"\"Given latent variables :obj:`z`, computes the binary cross\n",
    "        entropy loss for positive edges :obj:`pos_edge_index` and negative\n",
    "        sampled edges.\n",
    "\n",
    "        Args:\n",
    "            z (Tensor): The latent space :math:`\\mathbf{Z}`.\n",
    "            pos_edge_index (LongTensor): The positive edges to train against.\n",
    "        \"\"\"\n",
    "\n",
    "        pos_loss = -torch.log(\n",
    "            self.decoder(z, pos_edge_index, sigmoid=True) + EPS).mean()\n",
    "\n",
    "        # Do not include self-loops in negative samples\n",
    "        pos_edge_index, _ = remove_self_loops(pos_edge_index)\n",
    "        pos_edge_index, _ = add_self_loops(pos_edge_index)\n",
    "\n",
    "        neg_edge_index = negative_sampling(pos_edge_index, z.size(0))\n",
    "        neg_loss = -torch.log(1 -\n",
    "                              self.decoder(z, neg_edge_index, sigmoid=True) +\n",
    "                              EPS).mean()\n",
    "\n",
    "        return pos_loss + neg_loss\n",
    "\n",
    "\n",
    "    def test(self, z, pos_edge_index, neg_edge_index):\n",
    "        r\"\"\"Given latent variables :obj:`z`, positive edges\n",
    "        :obj:`pos_edge_index` and negative edges :obj:`neg_edge_index`,\n",
    "        computes area under the ROC curve (AUC) and average precision (AP)\n",
    "        scores.\n",
    "\n",
    "        Args:\n",
    "            z (Tensor): The latent space :math:`\\mathbf{Z}`.\n",
    "            pos_edge_index (LongTensor): The positive edges to evaluate\n",
    "                against.\n",
    "            neg_edge_index (LongTensor): The negative edges to evaluate\n",
    "                against.\n",
    "        \"\"\"\n",
    "        pos_y = z.new_ones(pos_edge_index.size(1))\n",
    "        neg_y = z.new_zeros(neg_edge_index.size(1))\n",
    "        y = torch.cat([pos_y, neg_y], dim=0)\n",
    "\n",
    "        pos_pred = self.decoder(z, pos_edge_index, sigmoid=True)\n",
    "        neg_pred = self.decoder(z, neg_edge_index, sigmoid=True)\n",
    "        pred = torch.cat([pos_pred, neg_pred], dim=0)\n",
    "\n",
    "        y, pred = y.detach().cpu().numpy(), pred.detach().cpu().numpy()\n",
    "\n",
    "        return roc_auc_score(y, pred), average_precision_score(y, pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the encoder and decoder that GAE will use\n",
    "# this code is slightly adapted from the PyG example to accept model_name\n",
    "class GAEEncoder(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(GAEEncoder, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels, 2 * out_channels, cached=True)\n",
    "        self.conv2 = GCNConv(2 * out_channels, out_channels, cached=True)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        return self.conv2(x, edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To decode embeddings and attempt input reconstruction, we can use the standard InnerProductDecoder\n",
    "class InnerProductDecoder(torch.nn.Module):\n",
    "    r\"\"\"The inner product decoder from the `\"Variational Graph Auto-Encoders\"\n",
    "    <https://arxiv.org/abs/1611.07308>`_ paper\n",
    "\n",
    "    .. math::\n",
    "        \\sigma(\\mathbf{Z}\\mathbf{Z}^{\\top})\n",
    "\n",
    "    where :math:`\\mathbf{Z} \\in \\mathbb{R}^{N \\times d}` denotes the latent\n",
    "    space produced by the encoder.\"\"\"\n",
    "    def forward(self, z, edge_index, sigmoid=True):\n",
    "        r\"\"\"Decodes the latent variables :obj:`z` into edge probabilities for\n",
    "        the given node-pairs :obj:`edge_index`.\n",
    "\n",
    "        Args:\n",
    "            z (Tensor): The latent space :math:`\\mathbf{Z}`.\n",
    "            sigmoid (bool, optional): If set to :obj:`False`, does not apply\n",
    "                the logistic sigmoid function to the output.\n",
    "                (default: :obj:`True`)\n",
    "        \"\"\"\n",
    "        value = (z[edge_index[0]] * z[edge_index[1]]).sum(dim=1)\n",
    "        return torch.sigmoid(value) if sigmoid else value\n",
    "\n",
    "    def forward_all(self, z, sigmoid=True):\n",
    "        r\"\"\"Decodes the latent variables :obj:`z` into a probabilistic dense\n",
    "        adjacency matrix.\n",
    "\n",
    "        Args:\n",
    "            z (Tensor): The latent space :math:`\\mathbf{Z}`.\n",
    "            sigmoid (bool, optional): If set to :obj:`False`, does not apply\n",
    "                the logistic sigmoid function to the output.\n",
    "                (default: :obj:`True`)\n",
    "        \"\"\"\n",
    "        adj = torch.matmul(z, z.t())\n",
    "        return torch.sigmoid(adj) if sigmoid else adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "super(type, obj): obj must be an instance or subtype of type",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-93-4c840f0066cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# in_channels (the dimensionality of the input data) is simply the number of features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# we define out_channels (the dimensionality of the latent vector or embedding) as 16\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGAE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGAEEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_channels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_channels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-91-d861e77e741b>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, in_channels, out_channels)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mGAEEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_channels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEncoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGCNConv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mout_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcached\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGCNConv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mout_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcached\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: super(type, obj): obj must be an instance or subtype of type"
     ]
    }
   ],
   "source": [
    "# bring the encoder and decoder together to compile the GAE\n",
    "# in_channels (the dimensionality of the input data) is simply the number of features\n",
    "# we define out_channels (the dimensionality of the latent vector or embedding) as 16\n",
    "model = GAE(GAEEncoder(in_channels=dataset.num_features, out_channels=16)).to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the optimizer with a learning rate of 0.01\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a writer to log training results\n",
    "writer = SummaryWriter(\"./log/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although we will train the GAE in an unsupervised manner (using reconstruction loss) <i>we can validate it's performance by testing it's ability to perform link prediction during training </i> (even though this is not used in back propagation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to test our predictions against the ground truth edges\n",
    "def test(pos_edge_index, neg_edge_index):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        z = model.encode(x, train_pos_edge_index)\n",
    "    return model.test(z, pos_edge_index, neg_edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000, AUC: 0.9666, AP: 0.9680\n",
      "Epoch: 100, AUC: 0.9596, AP: 0.9576\n",
      "Epoch: 200, AUC: 0.9510, AP: 0.9476\n",
      "Epoch: 300, AUC: 0.9488, AP: 0.9459\n",
      "Epoch: 400, AUC: 0.9483, AP: 0.9465\n",
      "Epoch: 500, AUC: 0.9456, AP: 0.9443\n",
      "Epoch: 600, AUC: 0.9463, AP: 0.9423\n",
      "Epoch: 700, AUC: 0.9445, AP: 0.9431\n",
      "Epoch: 800, AUC: 0.9452, AP: 0.9400\n",
      "Epoch: 900, AUC: 0.9512, AP: 0.9465\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "for epoch in range(0, 1000):\n",
    "    optimizer.zero_grad()\n",
    "    # get the embedding (z) of each node, shape(num_nodes, channels)\n",
    "    z = model.encode(x, train_pos_edge_index)\n",
    "    loss = model.recon_loss(z, train_pos_edge_index)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    writer.add_scalar(\"loss\", loss.item(), epoch)\n",
    "\n",
    "    auc, ap = test(data.test_pos_edge_index, data.test_neg_edge_index)\n",
    "    writer.add_scalar(\"AUC\", auc, epoch)\n",
    "    writer.add_scalar(\"AP\", ap, epoch)\n",
    "    if epoch % 100 == 0:\n",
    "        print('Epoch: {:03d}, AUC: {:.4f}, AP: {:.4f}'.format(epoch, auc, ap))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGAE Model\n",
    "To understand VGAEs, we again show the model as constructed by PyG (torch_geometric.nn.VGAE).\n",
    " \n",
    "VGAE differs from GAE in the use of two GCNs that encode the mean and variance. This allows it to reconstruct unseen inputs but requires a few updates to the main class.\n",
    "Namely:\n",
    "<ul>\n",
    "    <li>we use a KL loss, which uses the reconstruction loss from GAEs but adds a term to measure the probability distributions</li>\n",
    "    <li>the encoder uses the reparametrisation trick in order to maintain a differentiable loss function </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the VGAE class, which inherits from GAE \n",
    "\n",
    "class VGAE(GAE):\n",
    "    r\"\"\"The Variational Graph Auto-Encoder model from the\n",
    "    `\"Variational Graph Auto-Encoders\" <https://arxiv.org/abs/1611.07308>`_\n",
    "    paper.\n",
    "\n",
    "    Args:\n",
    "        encoder (Module): The encoder module to compute :math:`\\mu` and\n",
    "            :math:`\\log\\sigma^2`.\n",
    "        decoder (Module, optional): The decoder module. If set to :obj:`None`,\n",
    "            will default to the\n",
    "            :class:`torch_geometric.nn.models.InnerProductDecoder`.\n",
    "            (default: :obj:`None`)\n",
    "    \"\"\"\n",
    "    def __init__(self, encoder, decoder=None):\n",
    "        super(VGAE, self).__init__(encoder, decoder)\n",
    "\n",
    "    def reparametrize(self, mu, logvar):\n",
    "        if self.training:\n",
    "            return mu + torch.randn_like(logvar) * torch.exp(logvar)\n",
    "        else:\n",
    "            return mu\n",
    "\n",
    "    def encode(self, *args, **kwargs):\n",
    "        \"\"\"\"\"\"\n",
    "        self.__mu__, self.__logvar__ = self.encoder(*args, **kwargs)\n",
    "        self.__logvar__ = self.__logvar__.clamp(max=MAX_LOGVAR)\n",
    "        z = self.reparametrize(self.__mu__, self.__logvar__)\n",
    "        return z\n",
    "\n",
    "    def kl_loss(self, mu=None, logvar=None):\n",
    "        r\"\"\"Computes the KL loss, either for the passed arguments :obj:`mu`\n",
    "        and :obj:`logvar`, or based on latent variables from last encoding.\n",
    "\n",
    "        Args:\n",
    "            mu (Tensor, optional): The latent space for :math:`\\mu`. If set to\n",
    "                :obj:`None`, uses the last computation of :math:`mu`.\n",
    "                (default: :obj:`None`)\n",
    "            logvar (Tensor, optional): The latent space for\n",
    "                :math:`\\log\\sigma^2`.  If set to :obj:`None`, uses the last\n",
    "                computation of :math:`\\log\\sigma^2`.(default: :obj:`None`)\n",
    "        \"\"\"\n",
    "        mu = self.__mu__ if mu is None else mu\n",
    "        logvar = self.__logvar__ if logvar is None else logvar.clamp(\n",
    "            max=MAX_LOGVAR)\n",
    "        return -0.5 * torch.mean(\n",
    "            torch.sum(1 + logvar - mu**2 - logvar.exp(), dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a new encoder which incorporates new GCN layers for embedding the probability distribution\n",
    "class VGAEEncoder(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(VGAEEncoder, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels, 2 * out_channels, cached=True)\n",
    "        self.conv_mu = GCNConv(2 * out_channels, out_channels, cached=True)\n",
    "        self.conv_logvar = GCNConv(2 * out_channels, out_channels, cached=True)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        return self.conv_mu(x, edge_index), self.conv_logvar(x, edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bring the encoder and decoder together to compile the VGAE\n",
    "# in_channels (the dimensionality of the input data) is simply the number of features\n",
    "# we define out_channels (the dimensionality of the latent vector or embedding) as 16\n",
    "model = VGAE(VGAEEncoder(in_channels=dataset.num_features, out_channels=16)).to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# redefine the optimizer in order to reset it from the GAE training\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000, AUC: 0.6816, AP: 0.7143\n",
      "Epoch: 100, AUC: 0.8644, AP: 0.8791\n",
      "Epoch: 200, AUC: 0.8548, AP: 0.8708\n",
      "Epoch: 300, AUC: 0.8414, AP: 0.8578\n",
      "Epoch: 400, AUC: 0.8409, AP: 0.8598\n",
      "Epoch: 500, AUC: 0.8430, AP: 0.8583\n",
      "Epoch: 600, AUC: 0.8552, AP: 0.8681\n",
      "Epoch: 700, AUC: 0.8603, AP: 0.8688\n",
      "Epoch: 800, AUC: 0.8584, AP: 0.8650\n",
      "Epoch: 900, AUC: 0.8502, AP: 0.8597\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "for epoch in range(0, 1000):\n",
    "    optimizer.zero_grad()\n",
    "    # get the embedding (z) of each node, shape(num_nodes, channels)\n",
    "    z = model.encode(x, train_pos_edge_index)\n",
    "    loss = model.recon_loss(z, train_pos_edge_index)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    writer.add_scalar(\"loss\", loss.item(), epoch)\n",
    "\n",
    "    auc, ap = test(data.test_pos_edge_index, data.test_neg_edge_index)\n",
    "    writer.add_scalar(\"AUC\", auc, epoch)\n",
    "    writer.add_scalar(\"AP\", ap, epoch)\n",
    "    if epoch % 100 == 0:\n",
    "        print('Epoch: {:03d}, AUC: {:.4f}, AP: {:.4f}'.format(epoch, auc, ap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
